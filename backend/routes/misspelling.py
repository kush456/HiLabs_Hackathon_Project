from flask import Blueprint, request, jsonify
import pandas as pd
import json
import os

misspelling_bp = Blueprint('misspelling', __name__)

# Helper: fuzzy matching logic
try:
    from rapidfuzz import process, fuzz, distance
    _HAS_RAPIDFUZZ = True
except Exception:
    import difflib
    _HAS_RAPIDFUZZ = False

def standardize_with_meta(value, col, reps_json, metadata_json):
    if pd.isna(value) or str(value).strip() == "":
        return value
    val_str = str(value)
    meta = metadata_json.get(col, [])
    max_changes_allowed = int(meta[0]) if len(meta) > 0 else 9999
    threshold = float(meta[1]) if len(meta) > 1 else 90.0
    rep_key = meta[2] if len(meta) > 2 else col
    reps_list = reps_json.get(rep_key)
    if reps_list is None:
        reps_list = []
        reps_json[rep_key] = reps_list
    if val_str in reps_list:
        return val_str
    if not reps_list:
        reps_list.append(val_str)
        return val_str
    if _HAS_RAPIDFUZZ:
        match = process.extractOne(val_str, reps_list, scorer=fuzz.token_set_ratio)
        if not match:
            reps_list.append(val_str)
            return val_str
        best_choice, score, _ = match
        ed = distance.Levenshtein.distance(val_str, best_choice)
    else:
        best_choice = None
        best_score = -1.0
        for c in reps_list:
            sc = difflib.SequenceMatcher(None, val_str, c).ratio() * 100
            if sc > best_score:
                best_score = sc
                best_choice = c
        score = float(best_score)
        a, b = val_str, best_choice or ""
        ed = sum(1 for A, B in zip(a, b) if A != B) + abs(len(a) - len(b))
    if score >= threshold and ed <= max_changes_allowed:
        return best_choice
    else:
        if val_str not in reps_list:
            reps_list.append(val_str)
        return val_str

@misspelling_bp.route('/process/misspelling', methods=['POST'])
def handle_misspelling():
    """Correct misspellings in standardized CSV file using fuzzy matching and representatives."""
    try:
        # Always use the standardized_provider_roster.csv generated by standardization.py
        standardized_path = os.path.join('uploads', 'standardized_provider_roster.csv')
        if not os.path.exists(standardized_path):
            return jsonify({'error': 'Standardized provider roster file not found. Please run standardization first.'}), 400
        print(f"[misspelling.py] Using standardized file: {standardized_path}")
        df = pd.read_csv(standardized_path)

        # Representatives.json must still be uploaded
        # Always load representatives.json from the backend folder
        reps_path = os.path.join(os.path.dirname(__file__), '..', 'representatives.json')
        reps_path = os.path.abspath(reps_path)
        print(f"[misspelling.py] Loading representatives.json from backend directory: {reps_path}")
        if not os.path.exists(reps_path):
            return jsonify({'error': f'Representatives.json not found at {reps_path}'}), 400
        with open(reps_path, 'r', encoding='utf-8') as f:
            reps_json = json.load(f)

        # Metadata config (could be loaded from a file or hardcoded)
        metadata_json = {
            "credential" : [1,80,"credential"],
            "primary_specialty" : [2,65,"speciality"],
            "practice_city" : [2,65,"address_city"],
            "mailing_city" : [2,65,"address_city"],
            "medical_school" : [4,65,"medical_school"],
            "residency_program" : [4,65,"residency_program"],
            "area_p" : [2,65,"area"],
            "area_type_p" : [2,65,"area_type"],
            "area_type_m" : [2,65,"area_type"],
            "area_m" : [2,65,"area"]
        }
        # Apply standardization
        corrections_count = {col: 0 for col in metadata_json.keys()}

        for col in metadata_json.keys():
            # apply standardization column by column
            before = df[col].astype(str)  # original values (as string to compare safely)
            df[col] = df[col].apply(lambda v: standardize_with_meta(v, col, reps_json, metadata_json))
            after = df[col].astype(str)

            # count how many values actually changed
            corrections_count[col] = (before != after).sum()
            
        # Save output
        output_path = os.path.join('uploads', 'misspelling_corrected_provider_roster.csv')
        df.to_csv(output_path, index=False)
        
        # Save corrections count for quality score calculation
        corrections_json_path = os.path.join('uploads', 'corrections_count.json')
        # Convert numpy int64 to regular int for JSON serialization
        corrections_count_json = {k: int(v) for k, v in corrections_count.items()}
        with open(corrections_json_path, 'w', encoding='utf-8') as f:
            json.dump(corrections_count_json, f)
            
        return jsonify({
            'status': 'success',
            'message': 'Misspelling correction completed',
            'corrected_file': output_path,
            'corrections_count': corrections_count_json,
            'shape': df.shape,
            'columns': list(df.columns)
        })
    except Exception as e:
        return jsonify({'error': f'Error during misspelling correction: {str(e)}'}), 500
